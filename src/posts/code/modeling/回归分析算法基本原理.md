---
title: 回归分析算法基本原理
date: 2024-03-03
icon: circle-info
--- 

<!-- ![CE7703C839480A53E0C71A79279672AE](C:\Users\78661\Desktop\数学建模\CE7703C839480A53E0C71A79279672AE.png) -->










## 一元线性回归

一般地，称由 $y=\beta_0+\beta_1x+\epsilon$确定的模型为**一元线性回归模型**，记为
$$
\begin{cases}
y=\beta_0+\beta_1x+\epsilon\\
E\epsilon=0,D\epsilon=\sigma^2
\end{cases}
$$
固定的未知参数称为回归系数，自变量也称为回归变量
$$
Y=\beta_0+\beta_1x,称为y对x的回归直线方程
$$
一元线性回归分析的**主要任务**是：

1. 用试验值（样本值）对$\beta_0，\beta_1$和$\sigma$作点估计
2. 对回归系数$\beta_0，\beta_1$作假设检验
3. 在$x=x_0$处对$y$作预测，对$y$作区间估计

### 普通最小二乘法(Ordinary Least Square,OLS)

给定一组样本观测值$(X_i,Y_i),i=1,2,\cdots,n$，假如模型参数估计量已经求得，并且是最合理的参数估计量，那么样本回归函数应该能够最好地拟合样本数据，即样本回归线上的点与真实观测点的“总体误差”应该尽可能地小。

普通最小二乘法给出的判断标雅是:二者之差的平方和最小，即
$$
Q=\sum_{i=1}^n(Y_i-\widehat{Y})^2=\sum_{i=1}^n(Y_i-(\widehat{\beta}_0+\widehat{\beta}_1X_1))^2\\
记\begin{cases}
\bar{X}=\frac{1}{n}\sum{X_i}\\
\bar{Y}=\frac{1}{n}\sum{Y_i}\\
x_i=X_i-\bar{X}\\
y_i=Y_i-\bar{Y}\\
\end{cases}\\
则参数估计量可以写成：\\
\begin{cases}
\widehat{\beta}_1=\frac{\sum x_iy_i}{\sum x_i^2}\\
\widehat{\beta}_0=\bar{Y}-\widehat{\beta}_1\bar{X}
\end{cases}
$$
由于$Q=\sum_{i=1}^n(Y_i-\widehat{Y})^2=\sum_{i=1}^n(Y_i-(\widehat{\beta}_0+\widehat{\beta}_1X_1))^2$是$\widehat{\beta}_0,\widehat{\beta}_1$的二次函数，并且非负，所以其极小值总是存在的。

根据极值存在的条件，当$Q$对$\widehat{\beta}_0,\widehat{\beta}_1$的一阶偏导数为$0$时，$Q$达到最小，即
$$
\begin{cases}
\frac{\partial Q}{\partial\widehat{\beta}_0}=0\\
\frac{\partial Q}{\partial\widehat{\beta}_1}=0
\end{cases}
\Rightarrow
\begin{cases}
\sum(Y-\widehat{\beta}_0-\widehat{\beta}_iX_i)=0\\
\sum(Y_i-\widehat{\beta}_0-\widehat{\beta}_iX_i)X_i=0
\end{cases}
\Rightarrow
\begin{cases}
\sum Y_i=n\widehat{\beta}_i\sum X_i\\
\sum Y_iX_i=\widehat{\beta}_0\sum X_i+\widehat{\beta}_1\sum X_i^2
\end{cases}
$$

$$
解得：\\
\begin{cases}
\widehat{\beta}_1=\frac{n\sum Y_iX_i-\sum Y_i\sum X_i}{n\sum X_i^2-(\sum X_i)^2}\\
\widehat{\beta}_0=\bar{Y}-\widehat{\beta}_1\bar{X}
\end{cases}
$$

由于$\widehat{\beta}_0,\widehat{\beta}_1$的估计结果是从最小二乘法原理得到的，故称为最小二乘估计量（least-squares estimatiors）

### 可线性化的一元非线性回归（曲线回归）

1. 倒幂函数 $y=a+\frac{b}{x}$
2. 双曲线函数 $\frac{1}{y}=a+\frac{b}{x}$
3. 幂函数 $y=ax^b$
4. 指数函数 $y=ae^{bx}$
5. 倒指数函数 $y=ae^{\frac{b}{x}}$
6. 对数函数 $y=a+blnx$
7. S型曲线 $y=\frac{1}{a+be^{-x}}$

## 多元线性回归